{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2_master2TAL_2122_WSOL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TP 2: Linear Algebra and Feedforward neural network\n",
        "Master LiTL - 2021-2022\n",
        "\n",
        "## Requirements\n",
        "In this section, we will go through some code to learn how to manipulate matrices and tensors, and we will take a look at some PyTorch code that allows to define, train and evaluate a simple neural network. \n",
        "The modules used are the the same as in the previous session, *Numpy* and *Scikit*, with the addition of *PyTorch*. They are all already available within colab. \n",
        "\n",
        "## Part 1: Linear Algebra\n",
        "\n",
        "In this section, we will go through some python code to deal with matrices and also tensors, the data structures used in PyTorch.\n",
        "\n",
        "Sources:    \n",
        "* Linear Algebra explained in the context of deep learning: https://towardsdatascience.com/linear-algebra-explained-in-the-context-of-deep-learning-8fcb8fca1494\n",
        "* PyTorch tutorial: https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\n",
        "* PyTorch doc on tensors: https://pytorch.org/docs/stable/torch.html\n"
      ],
      "metadata": {
        "id": "FdJwlPN4mooh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Hk9fJuBVxk"
      },
      "source": [
        "## 1.1 Numpy arrays\n",
        "\n",
        "NumPy’s main object is the homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2IvCK4gPUAv",
        "outputId": "7da86b47-0ce9-4db5-99d7-5417478e5ba8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1,2])\n",
        "print(\"Our input vector with 2 elements:\\n\", x)\n",
        "print( \"x shape:\", x.shape)                \n",
        "\n",
        "print( \"x data type\", x.dtype)\n",
        "# Give a list of elements\n",
        "# a = np.array(1,2,3,4)    # WRONG\n",
        "# a = np.array([1,2,3,4])  # RIGHT\n",
        "\n",
        "# Generate a random matrix (with e generator, for reproducible results)\n",
        "rng = np.random.default_rng(seed=42)\n",
        "W = rng.random((3, 2))\n",
        "print(\"\\n Our weight matrix, of shape 3x2:\\n\", W)\n",
        "print( \"W shape:\", W.shape)\n",
        "print( \"W data type\", W.dtype)\n",
        "\n",
        "# Bias, a scalar\n",
        "b = 1\n",
        "\n",
        "# Now, try to multiply\n",
        "h = W.dot(x) + b\n",
        "print(\"\\n Our h layer:\\n\", h)\n",
        "print( \"h shape:\", h.shape)\n",
        "print( \"h data type\", h.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our input vector with 2 elements:\n",
            " [1 2]\n",
            "x shape: (2,)\n",
            "x data type int64\n",
            "\n",
            " Our weight matrix, of shape 3x2:\n",
            " [[0.77395605 0.43887844]\n",
            " [0.85859792 0.69736803]\n",
            " [0.09417735 0.97562235]]\n",
            "W shape: (3, 2)\n",
            "W data type float64\n",
            "\n",
            " Our h layer:\n",
            " [2.65171293 3.25333398 3.04542205]\n",
            "h shape: (3,)\n",
            "h data type float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKzJk0aaPUv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c828e9-4fe6-4eb8-dedc-4d42a4a8bbbf"
      },
      "source": [
        "# Useful transformations\n",
        "h = h.reshape((3,1))\n",
        "print(\"\\n h reshape:\\n\", h)\n",
        "print( \"h shape:\", h.shape)\n",
        "\n",
        "h1 = np.transpose(h)\n",
        "print(\"\\n h transpose:\\n\", h1)\n",
        "print( \"h shape:\", h1.shape)\n",
        "\n",
        "h2 = h.T\n",
        "print(\"\\n h transpose:\\n\", h2)\n",
        "print( \"h shape:\", h2.shape)\n",
        "\n",
        "Wt = W.T\n",
        "print(\"\\nW:\\n\", W)\n",
        "print(\"\\nW.T:\\n\", Wt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " h reshape:\n",
            " [[2.65171293]\n",
            " [3.25333398]\n",
            " [3.04542205]]\n",
            "h shape: (3, 1)\n",
            "\n",
            " h transpose:\n",
            " [[2.65171293 3.25333398 3.04542205]]\n",
            "h shape: (1, 3)\n",
            "\n",
            " h transpose:\n",
            " [[2.65171293 3.25333398 3.04542205]]\n",
            "h shape: (1, 3)\n",
            "\n",
            "W:\n",
            " [[0.77395605 0.43887844]\n",
            " [0.85859792 0.69736803]\n",
            " [0.09417735 0.97562235]]\n",
            "\n",
            "W.T:\n",
            " [[0.77395605 0.85859792 0.09417735]\n",
            " [0.43887844 0.69736803 0.97562235]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpIkzqN6PaJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862f469c-c469-4a94-ff2a-c76ef6c6ad4d"
      },
      "source": [
        "## numpy code to create identity matrix\n",
        "import numpy as np\n",
        "a = np.eye(4)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il-lX6VCA7gk"
      },
      "source": [
        "## 1.2 Tensors\n",
        "\n",
        "For neural networks implementation in PyTorch, we use tensors: \n",
        "* a specialized data structure that are very similar to arrays and matrices\n",
        "* used to encode the inputs and outputs of a model, as well as the model’s parameters\n",
        "* similar to NumPy’s ndarrays, except that tensors can run on GPUs or other specialized hardware to accelerate computing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPqpGGZPCRT-"
      },
      "source": [
        "### 1.2.1 Tensor initialization\n",
        "\n",
        "▶ **Look at the documentation to create tensors from existing data structures.**\n",
        "\n",
        "▶ **For each tensor created, print the tensor and its data type.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaEdsMG6BAh0",
        "outputId": "055f63fe-9b87-4f27-eef2-e8b6a0e9fbd2"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Tensor initialization\n",
        "\n",
        "## from any data. The data type is automatically inferred.\n",
        "data = [[1, 2], [3, 4]]\n",
        "# ...\n",
        "x_data = torch.tensor(data)\n",
        "print( \"x_data\", x_data)\n",
        "print( \"data type x_data=\", x_data.dtype)\n",
        "\n",
        "## from a numpy array specifically\n",
        "np_array = np.array(data)\n",
        "# ...\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(\"\\nx_np\", x_np)\n",
        "print( \"data type, np_array=\", np_array.dtype, \"x_data=\", x_np.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_data tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "data type x_data= torch.int64\n",
            "\n",
            "x_np tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "data type, np_array= int64 x_data= torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also create tensors filled with specific values, e.g.:\n",
        "\n",
        "▶ **Create a tensor with only 1s, another one with 0s with the specified *shape*.**\n",
        "\n",
        "▶ **Create a tensor filled with random values with the specified *shape*.**"
      ],
      "metadata": {
        "id": "8uBpyst4oQHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2, 3,) # shape is a tuple of tensor dimensions\n",
        "\n",
        "ones_tensor = torch.ones(shape)\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
        "\n",
        "rand_tensor = torch.rand(shape)\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I57vncUJoQS0",
        "outputId": "d0047cac-bb01-4603-da24-20aa3fb68c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Random Tensor: \n",
            " tensor([[0.3017, 0.3514, 0.5171],\n",
            "        [0.3135, 0.5903, 0.6895]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also override the values in an existing tensor, as below: replacing all values by 1, or by a random value in a range."
      ],
      "metadata": {
        "id": "zPj9tjy9n8QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## from another tensor\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"\\nOnes Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNskMUbEn8fl",
        "outputId": "fc18ed0e-b3da-43e2-8db7-566bb7cb61c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.9397, 0.5721],\n",
            "        [0.7637, 0.9425]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFDVEZcBCWF_"
      },
      "source": [
        "### 1.2.2 Tensor attributes\n",
        "\n",
        "Summary of the main attributes of a tensor:\n",
        "* shape\n",
        "* data type\n",
        "* device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS4TtR9DCJcq",
        "outputId": "b99c46cf-0ea4-4947-8e22-9605dcf50b33"
      },
      "source": [
        "# Tensor attributes\n",
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu8RM6O7CaKO"
      },
      "source": [
        "### 1.2.3 Move to GPU\n",
        "\n",
        "For now, our tensors should be on CPU. We want to move them to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT7n30VpCOzF",
        "outputId": "1f61d0bf-1d74-4414-9660-4203fd3fddb5"
      },
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "else:\n",
        "  print(\"no gpu\")\n",
        "\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n",
            "tensor([[7.1274e-01, 6.0618e-05, 3.5706e-01, 3.7572e-03],\n",
            "        [9.8634e-01, 8.7997e-01, 5.6103e-01, 4.0806e-01],\n",
            "        [1.7913e-01, 2.8863e-01, 6.9963e-01, 7.3479e-01]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdqHVRkHCcgq"
      },
      "source": [
        "**If you’re using Colab, allocate a GPU by going to Edit > Notebook Settings.**\n",
        "\n",
        "▶▶ **move to GPU, and re run last cells.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZPKBvOGsyf",
        "outputId": "e440e52a-b264-40a5-8792-f8c21748ce4d"
      },
      "source": [
        "import torch \n",
        "\n",
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "else:\n",
        "  print(\"no gpu\")\n",
        "\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device tensor is stored on: cuda:0\n",
            "tensor([[7.1274e-01, 6.0618e-05, 3.5706e-01, 3.7572e-03],\n",
            "        [9.8634e-01, 8.7997e-01, 5.6103e-01, 4.0806e-01],\n",
            "        [1.7913e-01, 2.8863e-01, 6.9963e-01, 7.3479e-01]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8um7SDWGCp8o"
      },
      "source": [
        "### 1.2.4 Tensor operations\n",
        "\n",
        "Doc: https://pytorch.org/docs/stable/torch.html\n",
        "\n",
        "Slicing operations:\n",
        "▶ **Check that the results of the code below corresponds to what you expected.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yLviqmYC3sZ",
        "outputId": "bb0f28f1-687c-44c9-d453-4c3c8a284cec"
      },
      "source": [
        "# Tensor operations: similar to numpy arrays\n",
        "\n",
        "tensor = torch.ones(4, 4)\n",
        "print(tensor)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# TODO: What do you expect?\n",
        "# ---------------------------------------------------------\n",
        "## Slicing\n",
        "print(\"\\nSlicing\")\n",
        "tensor[:,1] = 0 \n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "\n",
            "Slicing\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶ **Now modify the values in the first column.**"
      ],
      "metadata": {
        "id": "Y3I2GcbfpXOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# TODO: Change the first column with the value in l\n",
        "# ---------------------------------------------------------\n",
        "l =[1.,2.,3.,4.] \n",
        "l = torch.tensor( l )\n",
        "tensor[:, 0] = l\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkbbAuJEpXao",
        "outputId": "a52808e3-621d-4433-e006-3e5248bb3c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [2., 0., 1., 1.],\n",
            "        [3., 0., 1., 1.],\n",
            "        [4., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are other important operations on tensors:\n",
        "* concatenation\n",
        "* multiplication"
      ],
      "metadata": {
        "id": "0z65yiQcpka0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Concatenation\n",
        "print(\"\\nConcatenate\")\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)\n",
        "\n",
        "## Multiplication: element_wise\n",
        "print(\"\\nMultiply\")\n",
        "# This computes the element-wise product\n",
        "t2 = tensor.mul(tensor)\n",
        "print(f\"tensor.mul(tensor) \\n {t2} \\n\")\n",
        "# Alternative syntax:\n",
        "t3 = tensor * tensor\n",
        "print(f\"tensor * tensor \\n {t3}\")\n",
        "\n",
        "## Matrix multiplication\n",
        "t4 = tensor.matmul(tensor.T)\n",
        "print(f\"tensor.matmul(tensor.T) \\n {t4} \\n\")\n",
        "# Alternative syntax:\n",
        "t5 = tensor @ tensor.T\n",
        "print(f\"tensor @ tensor.T \\n {t5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbDEZ2Gapknh",
        "outputId": "adde60a6-01ac-4643-ed0c-cc6ea3ea24a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Concatenate\n",
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [2., 0., 1., 1., 2., 0., 1., 1., 2., 0., 1., 1.],\n",
            "        [3., 0., 1., 1., 3., 0., 1., 1., 3., 0., 1., 1.],\n",
            "        [4., 0., 1., 1., 4., 0., 1., 1., 4., 0., 1., 1.]])\n",
            "\n",
            "Multiply\n",
            "tensor.mul(tensor) \n",
            " tensor([[ 1.,  0.,  1.,  1.],\n",
            "        [ 4.,  0.,  1.,  1.],\n",
            "        [ 9.,  0.,  1.,  1.],\n",
            "        [16.,  0.,  1.,  1.]]) \n",
            "\n",
            "tensor * tensor \n",
            " tensor([[ 1.,  0.,  1.,  1.],\n",
            "        [ 4.,  0.,  1.,  1.],\n",
            "        [ 9.,  0.,  1.,  1.],\n",
            "        [16.,  0.,  1.,  1.]])\n",
            "tensor.matmul(tensor.T) \n",
            " tensor([[ 3.,  4.,  5.,  6.],\n",
            "        [ 4.,  6.,  8., 10.],\n",
            "        [ 5.,  8., 11., 14.],\n",
            "        [ 6., 10., 14., 18.]]) \n",
            "\n",
            "tensor @ tensor.T \n",
            " tensor([[ 3.,  4.,  5.,  6.],\n",
            "        [ 4.,  6.,  8., 10.],\n",
            "        [ 5.,  8., 11., 14.],\n",
            "        [ 6., 10., 14., 18.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( t1.device )\n",
        "\n",
        "tensor = torch.ones(4, 4, device='cuda')\n",
        "print(tensor)\n",
        "\n",
        "print(\"\\nConcatenate\")\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "\n",
        "print( t1.device )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-f_4wPHv4tr",
        "outputId": "afd678f4-509b-4d02-dcd3-9897ab0b4ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], device='cuda:0')\n",
            "\n",
            "Concatenate\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ulTT2k_Hs97"
      },
      "source": [
        "A tensor is stored on CPU by default.\n",
        "\n",
        "▶▶ **Now initialize *tensor* using *device='cuda'*: where are stored t1, ..., t5?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxW1jtX-GOfd"
      },
      "source": [
        "### 1.2.5 Exercise\n",
        "\n",
        "▶▶ **Compute the tensor *h = W.x + b*, using the same data for x and W as at the beginning of this TP.**\n",
        "\n",
        "```\n",
        "x = np.array([1,2])\n",
        "rng = np.random.default_rng(seed=42)\n",
        "W = rng.random((3, 2))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwIanFgWD_YJ",
        "outputId": "2c179b27-afb5-492e-e11c-12f24fe53da2"
      },
      "source": [
        "# --------------------------------------------------------\n",
        "# TODO: Write the code to compute h = W.x+b\n",
        "# --------------------------------------------------------\n",
        "\n",
        "# h = x.W + b\n",
        "x = torch.tensor([1,2])\n",
        "x = x.to( torch.float64) # be careful: using just 'float' here gives float32\n",
        "## OR\n",
        "#x = torch.tensor([1,2], dtype=float)\n",
        "print(\"Our input vector with 2 elements:\\n\", x)\n",
        "print( \"x shape:\", x.shape)\n",
        "print( \"x type:\", x.dtype )\n",
        "\n",
        "# Generate a random matrix (with e generator, for reproducible results)\n",
        "rng = np.random.default_rng(seed=42)\n",
        "W = rng.random((3, 2))\n",
        "W_t = torch.from_numpy(W)\n",
        "print(\"\\n Our weight matrix, of shape 3x2:\\n\", W)\n",
        "print( \"W shape:\", W_t.shape)\n",
        "print( \"W type:\", W.dtype)\n",
        "\n",
        "# Bias, a scalar\n",
        "b = 1.0\n",
        "\n",
        "# Now, try to multiply\n",
        "h_t = W_t.matmul(x) + b\n",
        "print(\"\\n Our h layer:\\n\", h_t)\n",
        "print( \"h shape:\", h_t.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our input vector with 2 elements:\n",
            " tensor([1., 2.], dtype=torch.float64)\n",
            "x shape: torch.Size([2])\n",
            "x type: torch.float64\n",
            "\n",
            " Our weight matrix, of shape 3x2:\n",
            " [[0.77395605 0.43887844]\n",
            " [0.85859792 0.69736803]\n",
            " [0.09417735 0.97562235]]\n",
            "W shape: torch.Size([3, 2])\n",
            "W type: float64\n",
            "\n",
            " Our h layer:\n",
            " tensor([2.6517, 3.2533, 3.0454], dtype=torch.float64)\n",
            "h shape: torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na_tJOnfGDIz"
      },
      "source": [
        "**Note:** when multiplying matrices, we need to have the same data type, e.g. not **x** with *int* and **W** with *float*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGmy-dtuOtiw"
      },
      "source": [
        "# Part 2: Feedforward Neural Network\n",
        "\n",
        "In this section, we will explore a simple neural network architecture for NLP applications ; specifically, we will train a feedforward neural network for sentiment analysis, using the same dataset of reviews as in the previous session.  We will also keep the bag of words representation. \n",
        "\n",
        "\n",
        "Sources:\n",
        "* This TP is inspired by a TP by Tim van de Cruys\n",
        "* https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/\n",
        "* https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
        "* https://medium.com/swlh/sentiment-classification-using-feed-forward-neural-network-in-pytorch-655811a0913f \n",
        "* https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdSyhJqpVczO"
      },
      "source": [
        "## 2.1 Read and load the data\n",
        "\n",
        "First, we need to understand how to use text data. Here we will keep the bag of word representation, as in the previous session. \n",
        "\n",
        "You can find different ways of dealing with the input data. The simplest solution is to use the DataLoader from PyTorch:    \n",
        "* the doc here https://pytorch.org/docs/stable/data.html and here https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "* an example of use, with numpy array: https://www.kaggle.com/arunmohan003/sentiment-analysis-using-lstm-pytorch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "You can also find many datasets for text ready to load in pytorch on: https://pytorch.org/text/stable/datasets.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxRbwziSV_BY"
      },
      "source": [
        "#### 2.1.1 Build BoW vectors\n",
        "\n",
        "The code below allows to use scikit methods you already know to generate the bag of word representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoVJ18s_oxkn",
        "outputId": "64259da7-045f-452f-eb91-834e830b6a44"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import sklearn\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# This will be the size of the vectors reprensenting the input\n",
        "MAX_FEATURES = 5000 \n",
        "\n",
        "# Load train and test set\n",
        "train = pd.read_csv(\"allocine_train.tsv\", header=0,\n",
        "                    delimiter=\"\\t\", quoting=3)\n",
        "dev = pd.read_csv(\"allocine_dev.tsv\", header=0,\n",
        "                    delimiter=\"\\t\", quoting=3)\n",
        "test = pd.read_csv(\"allocine_test.tsv\", header=0,\n",
        "                   delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "print(\"Creating features from bag of words...\")\n",
        "\n",
        "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
        "# bag of words tool.  \n",
        "vectorizer = CountVectorizer(\n",
        "    analyzer = \"word\",\n",
        "    max_features = MAX_FEATURES\n",
        ") \n",
        "\n",
        "# fit_transform() performs two operations; first, it fits the model\n",
        "# and learns the vocabulary; second, it transforms our training data\n",
        "# into feature vectors. The input to fit_transform should be a list of\n",
        "# strings.\n",
        "train_data_features = vectorizer.fit_transform(train[\"review\"])\n",
        "\n",
        "# output from vectorizer is a sparse array; our classifier needs a\n",
        "# dense array\n",
        "x_train = train_data_features.toarray()\n",
        "\n",
        "# construct a matrix of two columns (one for positive class, one for\n",
        "# negative class) where the correct class is indicated with 1 and the\n",
        "# incorrect one with 0\n",
        "y_train = np.asarray(train[\"sentiment\"])\n",
        "\n",
        "print( \"TRAIN:\", x_train.shape )\n",
        "count_train = x_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating features from bag of words...\n",
            "TRAIN: (5027, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt00MaMmW1_P"
      },
      "source": [
        "#### 2.1.2 Transform to tensors\n",
        "\n",
        "Now we need to transform our data to tensors, to provide them as input to PyTorch.\n",
        "\n",
        "* **torch.utils.data.TensorDataset(*tensors)**: Dataset wrapping tensors. Take tensors as inputs, obtained via **torch.from_numpy( an numpy array )**. Note: don't forget to transform tensor type to float, with **to(torch.float)** (or cryptic error saying it was expecting long...).\n",
        "* **DataLoader**: \n",
        "\n",
        "```\n",
        "DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=None,\n",
        "    pin_memory=False,\n",
        " )\n",
        " ```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMLPp3vnoxnG"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor dataset\n",
        "train_data = TensorDataset(torch.from_numpy(x_train).to(torch.float), torch.from_numpy(y_train))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 1 #no batch, or batch = 1\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOeZCY09o6CV"
      },
      "source": [
        "## 2.2 Neural Network\n",
        "\n",
        "Now we can build our learning model.\n",
        "\n",
        "We want here to build a simple feedforward neural network, with one hidden layer.\n",
        "\n",
        "This network takes as input bag of words vectors, exactly as our 'classic' models: each review is represented by a vector of the size the number of tokens in the vocabulary with '1' when a word is present and '0' for the other words. \n",
        "\n",
        "▶▶ **What is the input dimension?** \n",
        "\n",
        "▶▶ **What is the output dimension?** \n",
        "\n",
        "▶▶ **Now write the code to define the neural network:**\n",
        "\n",
        "In the __init__(...) function, you need to:\n",
        "- define a linear function that maps the input to the hidden dimensions (e.g. self.fc1)\n",
        "- define an activation function, using the non-linear function sigmoid (e.g. self.sigmoid)\n",
        "- define a second linear function, that takes the output of the hidden layer and maps to the output dimensions (e.g. self.fc2)\n",
        "\n",
        "In the forward(self, x) function, you need to:\n",
        "- pass the input *x* through the first linear function\n",
        "- pass the output of this linear application through the activation function\n",
        "- pass the final output through the second linear function and return its output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHLOE: TODO REMOVE CODE**"
      ],
      "metadata": {
        "id": "9uP5aV4f5VTM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvmc-_zqoxvF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(0) # For reproducibility: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function ==> W1\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # Non-linearity ==> g\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        # Linear function (readout) ==> W2\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        y = g(x.W1+b).W2\n",
        "        '''\n",
        "        # Linear function  # LINEAR ==> x.W1+b\n",
        "        out = self.fc1(x)\n",
        "\n",
        "        # Non-linearity  # NON-LINEAR ==> h1 = g(x.W1+b)\n",
        "        out = self.sigmoid(out) \n",
        "\n",
        "        # Linear function (readout)  # LINEAR ==> y = h1.W2\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSK0j8YASriA"
      },
      "source": [
        "▶▶ **What is the input dimension?** --> MAX FEATURES = 5000\n",
        "\n",
        "▶▶ **What is the output dimension?** --> number of classes = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWLDfLGxpBvn"
      },
      "source": [
        "We need to set up the values for the hyper-parameters, and define the form of the loss and the optimization methods.\n",
        "\n",
        "Note that we don't use here a SoftMax over the output of the final layer to obtain class probability: this is because this SoftMax application is done in the loss function chosen (*nn.CrossEntropyLoss()*). Be careful, it's not the case of all the loss functions available in PyTorch.\n",
        "\n",
        "▶▶ **What is the hidden dimension?** \n",
        "\n",
        "▶▶ **Note the hyper-parameters that would ne to be optimized, we'll see that later.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcGyjXbUoxx9"
      },
      "source": [
        "# Many choices here!\n",
        "VOCAB_SIZE = MAX_FEATURES\n",
        "input_dim = VOCAB_SIZE \n",
        "hidden_dim = 4\n",
        "output_dim = 2\n",
        "\n",
        "learning_rate = 0.1\n",
        "num_epochs = 5\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44c5TPBGSxSJ"
      },
      "source": [
        "▶▶ **What is the hidden dimension?**  --> 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPt_VbCMqoD2"
      },
      "source": [
        "### Training the network\n",
        "\n",
        "▶▶ **Now, we're going to train a model:**\n",
        "* Initialize a model using the class defined above\n",
        "* Define an optimizer, i.e. define the method we'll use to optimize / find the best parameters of our model: check the doc https://pytorch.org/docs/stable/optim.html and use the **SGD** optimizer. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO CHLOE REMOVE CODE**"
      ],
      "metadata": {
        "id": "-fftLrNH60m9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15WR_Jdtoxze"
      },
      "source": [
        "# Initialization of the model\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the code to train your model. \n",
        "\n",
        "A good indicator that your model is doing what is supposed to, is the loss: it should decrease during training. \n",
        "At the same time, the accuracy on the training set should increase.\n",
        "\n",
        "▶▶ **In the code below, we compute the loss and accuracy at the end of each training step (i.e. for each sample):**\n",
        "* Print the loss after each epoch during training\n",
        "* Print the accuracy after each epoch during training"
      ],
      "metadata": {
        "id": "eyuO4qN766GI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO CHLOE RM CODE**"
      ],
      "metadata": {
        "id": "gy94GlmZ_vv2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnNx8hZJox3v",
        "outputId": "4589e4bb-f6f0-4e9e-8abb-00a3459f8fda"
      },
      "source": [
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, total_acc, total_count = 0, 0, 0\n",
        "    for input, label in train_loader:\n",
        "\n",
        "        # Clearing the accumulated gradients\n",
        "        # torch *accumulates* gradients. Before passing in a\n",
        "        # new instance, you need to zero out the gradients from the old\n",
        "        # instance\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits \n",
        "        # = apply all our functions: y = g(x.W1+b).W2\n",
        "        outputs = model( input )\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, label)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        # Here is the way to find how to modify the parameters in\n",
        "        # order to lower the loss\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # -- a useful print\n",
        "        # Accumulating the loss over time\n",
        "        train_loss += loss.item()\n",
        "        total_acc += (outputs.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "\n",
        "    # Compute accuracy on train set at each epoch\n",
        "    # ...\n",
        "    print('Epoch: {}. Loss: {}. ACC {} '.format(epoch, train_loss/count_train, total_acc/count_train))\n",
        "        \n",
        "    total_acc, total_count = 0, 0\n",
        "    train_loss = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 0.5295901019196577. ACC 0.7232942112592003 \n",
            "Epoch: 1. Loss: 0.38159644401620024. ACC 0.8325044758305152 \n",
            "Epoch: 2. Loss: 0.3170426160692677. ACC 0.8669186393475233 \n",
            "Epoch: 3. Loss: 0.2811994798197802. ACC 0.8854187388104238 \n",
            "Epoch: 4. Loss: 0.2807111731653653. ACC 0.8838273324050129 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzMl5wdnqtCW"
      },
      "source": [
        "### Evaluate the model \n",
        "\n",
        "▶▶ **Process the dev data.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E81LmpAJq2ic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a737dad2-27cc-4883-acba-f4e3b9cd990e"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# TODO: Process the Test data\n",
        "# ---------------------------------------------\n",
        "\n",
        "#test = pd.read_csv(\"allocine_test.tsv\", header=0,\n",
        "#                   delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "dev_data_features = vectorizer.transform(dev[\"review\"])\n",
        "x_dev = dev_data_features.toarray()\n",
        "y_dev = np.asarray(dev[\"sentiment\"])\n",
        "\n",
        "print( \"DEV:\", x_dev.shape )\n",
        "\n",
        "# create Tensor datasets\n",
        "valid_data = TensorDataset(torch.from_numpy(x_dev).to(torch.float), torch.from_numpy(y_dev))\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEV: (549, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the code to compute the predictions of the model and compare to the gold labels. As before, we print a classification report. \n",
        "\n",
        "▶▶ **Run the code. The scores are not better than a simple Naive Bayes? We need to tune the hyper-parameters! But it could be the case that a simple model is better than a neural based... Always consider running a simple algorithm before going to more complex ones.**"
      ],
      "metadata": {
        "id": "fkG_m9mpAhrv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldDubAPDox5K",
        "outputId": "15479ad2-6842-433f-e0be-ab5363538bec"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions = []\n",
        "gold = []\n",
        "\n",
        "# Disabling gradient calculation is useful for inference, \n",
        "# when you are sure that you will not call Tensor.backward(). \n",
        "with torch.no_grad():\n",
        "    for input, label in valid_loader:\n",
        "        probs = model(input)\n",
        "        predictions.append( torch.argmax(probs, dim=1).cpu().numpy()[0] )\n",
        "        gold.append(int(label))\n",
        "\n",
        "print(classification_report(gold, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.81       230\n",
            "           1       0.86      0.85      0.86       319\n",
            "\n",
            "    accuracy                           0.84       549\n",
            "   macro avg       0.83      0.83      0.83       549\n",
            "weighted avg       0.84      0.84      0.84       549\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-jspmLL387"
      },
      "source": [
        "## 3. Move to GPU\n",
        "\n",
        "One important issue with NN is their computational cost: here, the code runs fast, but we often need to use GPU instead of CPU to run NN models. See below what changes have to be made when initializing the model and when training it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pydK_h3QLZfO",
        "outputId": "350e6906-b362-49e9-d4da-ae66a92953be"
      },
      "source": [
        "## 1- Define the device to be used\n",
        "\n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method to move a tensor to GPU is *to()*: https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to.\n",
        "\n",
        "▶▶ **Once initialized, move to model to GPU using:**\n",
        "```\n",
        "model = model.to(device)\n",
        "```\n",
        "\n",
        "**TODO CHLODE RM CODE**"
      ],
      "metadata": {
        "id": "k5SePDMzX3i3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7mmAyoPMziY"
      },
      "source": [
        "## 3- Move your model to the GPU\n",
        "\n",
        "# Initialization of the model\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶▶ **Now move the data, i.e. input and label, using the same method, e.g.:**\n",
        "```\n",
        "input = input.to(device)\n",
        "```\n",
        "\n",
        "**TODO CHLOE RM CODE**"
      ],
      "metadata": {
        "id": "Y3XHhXWYYb2q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANibLgnhL9jU",
        "outputId": "3929b2eb-df15-4239-e066-8bb50da8824f"
      },
      "source": [
        "## 4- Move your data to GPU\n",
        "\n",
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, total_acc, total_count = 0, 0, 0\n",
        "    for input, label in train_loader:\n",
        "        ## ------------ CHANGE HERE -----------------\n",
        "        input = input.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model( input )\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, label)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulating the loss over time\n",
        "        train_loss += loss.item()\n",
        "        total_acc += (outputs.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "\n",
        "    # Compute accuracy on train set at each epoch\n",
        "    print('Epoch: {}. Loss: {}. ACC {} '.format(epoch, train_loss/count_train, total_acc/count_train))\n",
        "        \n",
        "    total_acc, total_count = 0, 0\n",
        "    train_loss = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 0.5201658111256726. ACC 0.7336383528943704 \n",
            "Epoch: 1. Loss: 0.36919306652012396. ACC 0.8400636562562165 \n",
            "Epoch: 2. Loss: 0.29851252123677274. ACC 0.8768649293813408 \n",
            "Epoch: 3. Loss: 0.26750923704391744. ACC 0.889596180624627 \n",
            "Epoch: 4. Loss: 0.2565383207324902. ACC 0.8961607320469465 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to move the data when predicting labels, as you can see below."
      ],
      "metadata": {
        "id": "SwwmwzhXZE8E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSXQF-ViNUH4",
        "outputId": "472735ef-cf7d-4e1b-eec2-b6a7212117d3"
      },
      "source": [
        "# -- 5- Again, move your data to GPU\n",
        "predictions, gold = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for input, label in valid_loader:\n",
        "        ## ------------ CHANGE HERE -----------------\n",
        "        input = input.to(device)\n",
        "\n",
        "        probs = model(input)\n",
        "        #Here, we need CPU: else, it will generate the following error\n",
        "        # can't convert cuda:0 device type tensor to numpy. \n",
        "        # Use Tensor.cpu() to copy the tensor to host memory first.\n",
        "        # (if we need a numpy array)\n",
        "        predictions.append( torch.argmax(probs, dim=1).cpu().numpy()[0] )\n",
        "        #print( probs )\n",
        "        #print( torch.argmax(probs, dim=1) ) # Return the index of the max value\n",
        "        #print( torch.argmax(probs, dim=1).cpu().numpy()[0] )\n",
        "        gold.append(int(label))\n",
        "\n",
        "print(classification_report(gold, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.64      0.74       230\n",
            "           1       0.78      0.94      0.85       319\n",
            "\n",
            "    accuracy                           0.81       549\n",
            "   macro avg       0.83      0.79      0.80       549\n",
            "weighted avg       0.83      0.81      0.81       549\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 3: using continuous representation\n",
        "\n",
        "In this part, we will use continuous representations of words, namely Continuous Bag of Words that is randomly initialized embeddings (we'll try pretrained embeddings later).\n",
        "\n",
        "In order to create the representation of a document, we will take all the embeddings of the words that appear in the document, and sum them together or take their average.\n",
        "So instead of having an input vector of size 5000, we now have an input vector of size e.g. 50, that represents the ‘average’, combined meaning of all the words in the document taken together. \n",
        "\n",
        "Crucially,  the  neural  network  will  also  learn  the  embeddings  during  training :  the  embeddings  of  the network are also parameters that are optimized according to the loss function.\n",
        "\n",
        "The dataset remains the French set of reviews labeled with sentiment.\n",
        "\n",
        "We will compare our model to the scores obtained previously with bag of word representations.\n",
        "\n"
      ],
      "metadata": {
        "id": "vH5PWlKbb2H_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Load the data\n",
        "\n",
        "\n",
        "\n",
        "### Read the data\n",
        "\n",
        "Here, we're not using the vectorizer from Scikit, the code below allows to extract the text and labels."
      ],
      "metadata": {
        "id": "0OYQMyJVtbYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"allocine_train.tsv\"\n",
        "dev_path = \"allocine_dev.tsv\"\n",
        "test_path = \"allocine_test.tsv\"\n",
        "\n",
        "# Load train set\n",
        "train_df = pd.read_csv(train_path, header=0, delimiter=\"\\t\", quoting=3)\n",
        "train_iter = []\n",
        "for i in train_df.index:\n",
        "    train_iter.append( tuple( [train_df[\"sentiment\"][i], train_df[\"review\"][i]] ) )\n",
        "\n",
        "print( '\\n'.join( [ str(train_iter[i][0])+'\\t'+train_iter[i][1] for i in range(0,10) ] ) )\n",
        "\n",
        "dev_df = pd.read_csv(dev_path, header=0, delimiter=\"\\t\", quoting=3)\n",
        "dev_iter = []\n",
        "for i in dev_df.index:\n",
        "    dev_iter.append( tuple( [dev_df[\"sentiment\"][i], dev_df[\"review\"][i]] ) )\n",
        "\n",
        "test_iter = []\n",
        "test_df = pd.read_csv(test_path, header=0, delimiter=\"\\t\", quoting=3)\n",
        "for i in test_df.index:\n",
        "    test_iter.append( tuple( [test_df[\"sentiment\"][i], test_df[\"review\"][i]] ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPgeP14otzxk",
        "outputId": "c65c0bce-c04f-48b4-c43f-4b4a2c066211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\tStephen King doit bien ricaner en constatant cette navrante histoire de disparus, les scénaristes semblent s'être inspirés de ses oeuvres mais ont bien moins son talent que celui du business. Quel perte de temps que de regarder ces personnages perdus au centre d'une histoire sans fin et sans intérêt, où 2 ou 3 épisodes suffisent pour décrocher, à l'inverse d'une série comme Desperate housewives dont les dialogues, les scénarii et les personnages contribuent sans cesse à relancer l'intérêt et le plaisir au fil des épisodes. Pourtant mes goûts initiaux m'auraient porté davantage du côté de la série fantastique. Il ne faut préjuger de rien! A bon entendeur...\n",
            "1\tExcellentissime! Une série à l'apparence toute calme et lisse, qui se révèle être un véritable noeud de problèmes, de secrets, de mensonges... Les actrices sont vraiment toutes très bonnes dans leurs rôles, avec une petite préférence pour Bree, qui pète complètement un câble à la fin de la saison 2!\n",
            "0\tVoir de pareilles évaluations me conforte dans l'idée de ne pas expliquer comment utiliser internet a ma grand mère !! Les francais devrait arreter de tenter de faire des séries TV !!!\n",
            "0\tQuand je pense qu'il ya des séries géniales qui sont arrètées car fautes d'audiences (séries us bien sur). Et la on maintien ce truc pour une quatrième saison... D'ailleurs la preuve que la série est nulle: a-t-elle rencontré le succès aux US?\n",
            "0\tCette série est nul tout les médecins couche entre eux. Il n'y a que du tout le monde couche avec tout le monde et rien d'autre. Ce n'est pas la réalité et c'est ennuyeux. On c'est meme pas qui couche avec qui.\n",
            "0\tLes Feux de L'Amour est un chef d'oeuvre à côté tant par les dialogues que par les scénarios. Attention, tu fumes une et une seule cigarette à 17 ans, tu vas pourrir en enfer. Tu bois un seul verre d'alcool à 21 ans, tu es un alcoolique. Dans Les Feux de l'Amour au moins les personnages ne sont pas lisses. Ici, tout le monde est beau, tout le monde est gentil. Si vous avez des tendances suicidaires, ne regardez pas la série! Vous risquez de passer à l'acte.\n",
            "0\tUne des pires séries que j'ai eu l'occasion de voir, les scénarii sont d'un plat, tellement prévisibles que c'en est affligeant, les dialogues sont surréalistes, de même que les actions, à 16 ans toutes les filles tombent enceintes, boivent, couchent avec tous le monde sans s'en souvenir le lendemain, sans parler des garçons, je ne sais pas combien de fois on nous répéte dans la série à quel point Lucas est \"le bon garçon\", il couche avec les filles sans protection et certaines fois sans les connaître, boit et se tatoue... humm quel excellent exemple vraiment, la série de l'année.\n",
            "1\tImpressionant tant cette série est captivante.Lost c'est l'art de faire monter l'adrénaline d'un coup.De plus les acteurs sont vraiments bons.Parfois on rigole aussi.Bref une série incroyable qui tient en haleine !\n",
            "1\tCette serie est une drogue, apres avoir vu un ou deux épisodes comme ça sans trop d'interêt on veut absolument connaitre la suite afin de savoir pourquoi Marie Alice est morte. Chaque épisode est incroyablement bien pensé et différent, tout les acteurs sont parfait dans leurs roles. Attention de ne pas manquer d'épisodes sous peine d'etre perdu^^ Je tire enfin mon chapeau a Danny Elfman qui nous offre encore un superbe thème musical dont on ne se lasse pas de l'écouter et de le réécouter.\n",
            "0\tOriginale ? Non. L'histoire : des naufragés jouent a Ko Lantha sur une ile ou il se passe des choses etranges. C'est filmé comme du Alias : sans style (je regrette homicide ou Oz qui étaient des series originale autant par les scénars, le traitement et la manière de filmer.). Les personnages sont nuls : Le docteur charismatique et heroique, La tête de mule au grand coeur, La fille gentille mais qui est poursuivie par la justice etc... David Lynch je t'en prie, reviens !!!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We need to tokenize our data, and build the corresponding vocabulary (on the train set)."
      ],
      "metadata": {
        "id": "pS2jdf2Vt1Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# splits the string sentence by space.\n",
        "tokenizer = get_tokenizer( None ) \n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "ZBctRAcZsQSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vocabulary\n",
        "\n",
        "Here the vocabulary is a specific object in Pytorch, check the existing functions to use it here: https://pytorch.org/text/stable/vocab.html\n",
        "\n",
        "For example, the vocabulary directly converts a list of tokens into integers."
      ],
      "metadata": {
        "id": "Tus9Kedas5dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['Avant', 'cette', 'série', ','])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb6TYA9Is5v6",
        "outputId": "6386ca9a-7a13-4d41-c725-ad4b785a18ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2910, 18, 7, 144]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶▶ **Now, try to retrieve the indice of the word 'mauvais'.** \n",
        "\n",
        "**TODO CHLOE RM CODE**"
      ],
      "metadata": {
        "id": "3aAwvzFavjIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print( vocab.lookup_indices( ['mauvais'] ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9cKqyj3vjT8",
        "outputId": "14cd1a9c-a33b-437c-b010-e190fcad7c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[246]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text and label pipelines\n",
        "\n",
        "The text pipeline converts a text string into a list of integers based on the lookup table defined in the vocabulary. \n",
        "\n",
        "The label pipeline converts the label into integers. "
      ],
      "metadata": {
        "id": "_4zDQHrstB12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) #simple mapping to self"
      ],
      "metadata": {
        "id": "eUNfcXNUtCBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline('Avant cette série, je ne connaissais que Urgence')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArT6VMS23I0i",
        "outputId": "3158bcf9-5817-4098-b799-3ece7cf8c384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2910, 18, 89, 16, 17, 6120, 8, 10529]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline('0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LySlUUzY3FEE",
        "outputId": "dd4b0477-123e-40af-abfa-c2d095e346d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate data batches and iterator\n",
        "\n",
        "We also use *torch.utils.data.DataLoader* with an iterable dataset, here a simple list of labels and text reviews, as saved in *train_iter*.\n",
        "\n",
        "Before sending to the model, we apply a function, *collate_fn*, to our input data:\n",
        "* The input to *collate_fn* is a batch of data with the batch size in *DataLoader*, \n",
        "* *collate_fn* processes them according to the data processing pipelines declared previously. \n",
        "\n",
        "In 'collate_batch', we define how we want to pre-process our data.\n",
        "\n",
        "The function is directly called within *DataLoader*:\n",
        "```\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "```\n",
        "\n",
        "Below: \n",
        "* the text entries in the original data batch input are packed into a list and concatenated as a single tensor. \n",
        "* the offset is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor\n",
        "* Label is a tensor saving the labels of individual text entries.\n",
        "\n",
        "The offsets are used to retrieve the individual sequences in the each batch (the sequences are concatenated)."
      ],
      "metadata": {
        "id": "Nj21QrBotJrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label.to(device), text_list.to(device), offsets.to(device)\n",
        "\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "GE82N6mmuxYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Define the models\n",
        "\n",
        "This time the FFNN will have an embedding layer that transforms our input words to vectors of size 'embed_dim' and performs an operation on these vectors to build a representation for each document (default=mean).\n",
        "\n",
        "More specifically, we'll use the *nn.EmbeddingBag* layer: https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html\n",
        "\n",
        "* mode (string, optional) – \"sum\", \"mean\" or \"max\". Default=mean.\n",
        "\n",
        "**Exercise: __init__():**\n",
        "\n",
        "▶▶ **Define the embedding layer in the __init__() function below.**\n",
        "\n",
        "▶▶ **Define a FFNN as previously, using one linear function, an activation function, and a linear projection to the output.**\n",
        "\n",
        "The code of the *forward* function is given. This time, it has a 2nd argument: the 'offsets' are used to retrieve the individual documents (each document is concatenated to the others in a batch, the offsets are used to retrieve the separate documents).\n",
        "\n",
        "**TODO CHLOE RM CODE**"
      ],
      "metadata": {
        "id": "7PRplEud9XHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedforwardNeuralNetModel2(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel2, self).__init__()\n",
        "\n",
        "        # Embedding layer \n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        # Linear function ==> W1\n",
        "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
        "\n",
        "        # Non-linearity ==> g\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        # Linear function (readout) ==> W2\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        # Linear function  # LINEAR ==> x.W1+b\n",
        "        out = self.fc1(embedded)\n",
        "\n",
        "        # Non-linearity  # NON-LINEAR ==> h1 = g(x.W1+b)\n",
        "        out = self.sigmoid(out) \n",
        "\n",
        "        # Linear function (readout)  # LINEAR ==> y = h1.W2\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "CVWapsW2sQ2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Train and evaluation\n",
        "\n",
        "To use the offsets, we need to slightly modify the train and evaluation procedures."
      ],
      "metadata": {
        "id": "UsXmIGqApbxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_woffset( model, train_loader, optimizer, num_epochs=5 ):\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, total_acc, total_count = 0, 0, 0\n",
        "        for label, input, offsets in train_loader:\n",
        "            input = input.to(device)\n",
        "            label = label.to(device)\n",
        "            # Step1. Clearing the accumulated gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Step 2. Forward pass to get output/logits\n",
        "            outputs = model( input, offsets )\n",
        "            # Step 3. Compute the loss, gradients, and update the parameters by\n",
        "            # calling optimizer.step()\n",
        "            # - Calculate Loss: softmax --> cross entropy loss\n",
        "            loss = criterion(outputs, label)\n",
        "            # - Getting gradients w.r.t. parameters\n",
        "            loss.backward()\n",
        "            # - Updating parameters\n",
        "            optimizer.step()\n",
        "            # Accumulating the loss over time\n",
        "            train_loss += loss.item()\n",
        "            total_acc += (outputs.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "        # Compute accuracy on train set at each epoch\n",
        "        print('Epoch: {}. Loss: {}. ACC {} '.format(epoch, train_loss/count_train, total_acc/count_train))\n",
        "        total_acc, total_count = 0, 0\n",
        "        train_loss = 0\n",
        "\n",
        "def evaluate_woffset( model, dev_loader ):\n",
        "    predictions = []\n",
        "    gold = []\n",
        "    with torch.no_grad():\n",
        "        for label, input, offsets in dev_loader:\n",
        "            input = input.to(device)\n",
        "            label = label.to(device)\n",
        "            probs = model(input, offsets)\n",
        "            # -- MODIFIED to deal with batches\n",
        "            predictions.extend( torch.argmax(probs, dim=1).cpu().numpy() ) # <-----\n",
        "            gold.extend([int(l) for l in label])\n",
        "    print(classification_report(gold, predictions))\n",
        "    return gold, predictions"
      ],
      "metadata": {
        "id": "US_0JmN5phqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Run experiments\n",
        "\n",
        "The code below uses the FFNN with continuous representations."
      ],
      "metadata": {
        "id": "NC2VtTmv-Q_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "batch_size = 1\n",
        "train_loader = DataLoader(train_iter, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "dev_loader = DataLoader(dev_iter, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "TBB9S0NBqNLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the values of the hyperparameters\n",
        "vocab_size = len(vocab)\n",
        "emb_dim = 300\n",
        "hidden_dim = 4\n",
        "output_dim = 2\n",
        "learning_rate = 0.1\n",
        "num_epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Jod8FnWPs_Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model_ffnn2 = FeedforwardNeuralNetModel2(vocab_size, emb_dim, hidden_dim, output_dim)\n",
        "optimizer = torch.optim.SGD(model_ffnn2.parameters(), lr=learning_rate)\n",
        "model_ffnn2 = model_ffnn2.to(device)\n",
        "# Train the model\n",
        "train_woffset( model_ffnn2, train_loader, optimizer, num_epochs=5 )\n",
        "# Evaluate on dev\n",
        "gold, pred = evaluate_woffset( model_ffnn2, dev_loader )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xug7ygbpAhS",
        "outputId": "09f78cfe-4680-4d15-e361-676f6ab06b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 0.6422858452885715. ACC 0.6299980107419932 \n",
            "Epoch: 1. Loss: 0.5580713001348676. ACC 0.7163318082355281 \n",
            "Epoch: 2. Loss: 0.497581498553172. ACC 0.7529341555599761 \n",
            "Epoch: 3. Loss: 0.4519847773106927. ACC 0.7869504674756316 \n",
            "Epoch: 4. Loss: 0.4103179189151622. ACC 0.8088323055500298 \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.90      0.71       230\n",
            "           1       0.89      0.55      0.68       319\n",
            "\n",
            "    accuracy                           0.70       549\n",
            "   macro avg       0.74      0.72      0.69       549\n",
            "weighted avg       0.76      0.70      0.69       549\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶▶ **Plot the loss during training (i.e. loss wrt to iterations).**\n",
        "\n",
        "▶▶ **The performance are low: why? what could we do to improve these scores?**"
      ],
      "metadata": {
        "id": "JAKfLOwB9kE2"
      }
    }
  ]
}